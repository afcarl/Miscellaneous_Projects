#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Sat Nov  5 12:16:02 2016

@author: priyankadwivedi
"""

# Harris corner detection
# Good feature detection
#http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_shi_tomasi/py_shi_tomasi.html
import numpy as np
import cv2
from matplotlib import pyplot as plt

import os
paths = "/Users/priyankadwivedi/Documents/Projects/imageprocessing"
filename = os.path.join(paths, "cardboard.jpg")
img = cv2.imread(filename)
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
print(gray.shape, gray.size, gray.dtype)

corners = cv2.goodFeaturesToTrack(gray,8,0.01,10)
corners = np.int0(corners)

for i in corners:
    x,y = i.ravel()
    cv2.circle(img,(x,y),3,255,-1)

plt.imshow(img),plt.show()

## Implement SIFT
#http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html
 
# load the image we are going to extract descriptors from and convert
# it to grayscale
filename1 = os.path.join(paths, "tajmahal1.jpg")
filename2 = os.path.join(paths, "tajmahal2.jpg")
img1 = cv2.imread(filename1,0)          # queryImage
img2 = cv2.imread(filename2,0) # trainImage

# Initiate SIFT detector
sift = cv2.SIFT()

# find the keypoints and descriptors with SIFT
kp1, des1 = sift.detectAndCompute(img1,None)
kp2, des2 = sift.detectAndCompute(img2,None)

print(len(kp1), len(kp2))
# FLANN parameters
FLANN_INDEX_KDTREE = 0
index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
search_params = dict(checks=50)   # or pass empty dictionary

flann = cv2.FlannBasedMatcher(index_params,search_params)

matches = flann.knnMatch(des1,des2,k=2)

# Need to draw only good matches, so create a mask
matchesMask = [[0,0] for i in xrange(len(matches))]

# ratio test as per Lowe's paper
for i,(m,n) in enumerate(matches):
    if m.distance < 0.7*n.distance:
        matchesMask[i]=[1,0]

draw_params = dict(matchColor = (0,255,0),
                   singlePointColor = (255,0,0),
                   matchesMask = matchesMask,
                   flags = 0)

img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches,None,**draw_params)

## Image Thresholding
# http://opencv24-python-tutorials.readthedocs.io/en/stable/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html
paths1 = "C:\Users\s6324900\Desktop\Deep learning\Pytesser"
filename3 = os.path.join(paths1, "nishu.JPG")
#read as a gray image
img1 = cv2.imread(filename3,0)     
print(img1.shape, img1.size, img1.dtype)

cv2.imshow('image',img1)
cv2.waitKey(0)

#img1 = cv2.medianBlur(img1,5)

## Try differemt thresholding operations
#1. Global Thresholding
# second value is the threshold, 3rd is value for pixel if > than threshold
ret,th1 = cv2.threshold(img1,100,255,cv2.THRESH_BINARY)

# Otsu's thresholding - Pass 0 as the threshold value
ret2,th2 = cv2.threshold(img1,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)


# Otsu's thresholding after Gaussian filtering
blur = cv2.GaussianBlur(img1,(5,5),0)
ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)

print(ret, ret2, ret3)
# plot all the images and their histograms
images = [img1, 0, th1,
          img1, 0, th2,
          blur, 0, th3]
titles = ['Original Noisy Image','Histogram','Global Thresholding (v=100)',
          'Original Noisy Image','Histogram',"Otsu's Thresholding",
          'Gaussian filtered Image','Histogram',"Otsu's Thresholding"]

for i in xrange(3):
    plt.figure(figsize=(8,8))
    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')
    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])
    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)
    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])
    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')
    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])
plt.show()

plt.figure(figsize=(8,8))
plt.imshow(th3, 'gray')

## Lets try Canny edge on Threshold 2
edges = cv2.Canny(th1,50,150)
plt.figure(figsize=(8,8))
plt.imshow(edges, 'gray')

#Adaptive thresholding where different threhsolds are used for different areas in the image

th2 = cv2.adaptiveThreshold(img1,255,cv2.ADAPTIVE_THRESH_MEAN_C,\
            cv2.THRESH_BINARY,11,2)
th3 = cv2.adaptiveThreshold(img1,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY,11,2)

titles = ['Original Image', 'Global Thresholding (v = 127)',
            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']
images = [img1, th1, th2, th3]

for i in xrange(4):
    plt.figure(figsize=(8,8))
    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')
    plt.title(titles[i])
    plt.xticks([]),plt.yticks([])
plt.show()


#Video analysis
#Video background noise substraction
#http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_bg_subtraction/py_bg_subtraction.html

